---
layout: default
title: Models | Lookinglass
description: Complete guide to Lookinglass AI models. Compare 13 Chat models and 7 O-series models, understand Flex pricing, context windows, and choose the right model for your needs.
---

<section class="legal-page">
    <div class="legal-container">
        <div class="legal-header">
            <h1>AI Models Guide</h1>
            <p class="legal-updated">Choose the right model for every task</p>
        </div>
        
        <div class="legal-content">
            <div class="legal-intro">
                <p>Lookinglass gives you access to 20 OpenAI models across two families: 13 Chat models for fast, versatile conversations and 7 O-series models for complex reasoning tasks. This guide helps you choose the right model and settings for your needs.</p>
            </div>

            <h2>Chat Models vs O-Series Models</h2>
            
            <div class="models-comparison">
                <div class="models-type-card">
                    <h3>Chat Models (13 available)</h3>
                    <p><strong>Best for:</strong> General conversations, creative writing, code generation, quick questions, and most everyday AI tasks.</p>
                    <ul>
                        <li><strong>Speed:</strong> Fast responses, typically 1-5 seconds</li>
                        <li><strong>Cost:</strong> Generally lower cost per message</li>
                        <li><strong>Control:</strong> Temperature setting (0.0-2.0) for creativity control</li>
                        <li><strong>Flexibility:</strong> 5 models support Flex pricing for 50% savings</li>
                    </ul>
                </div>
                
                <div class="models-type-card">
                    <h3>O-Series Models (7 available)</h3>
                    <p><strong>Best for:</strong> Complex reasoning, mathematical problems, code debugging, research, and tasks requiring deep thinking.</p>
                    <ul>
                        <li><strong>Reasoning:</strong> Advanced step-by-step thinking process</li>
                        <li><strong>Quality:</strong> Higher accuracy on complex problems</li>
                        <li><strong>Control:</strong> Effort levels (Low/Medium/Hard) instead of temperature</li>
                        <li><strong>Time:</strong> Slower responses as models "think" before answering</li>
                    </ul>
                </div>
            </div>

            <h2>Available Chat Models</h2>
            
            <div class="models-grid">
                <div class="models-card">
                    <h4>GPT-5 Family</h4>
                    <ul>
                        <li><strong>GPT-5</strong> - Latest flagship model <span class="models-flex-badge">Flex</span></li>
                        <li><strong>GPT-5 mini</strong> - Balanced performance and cost <span class="models-flex-badge">Flex</span></li>
                        <li><strong>GPT-5 nano</strong> - Fast and economical <span class="models-flex-badge">Flex</span></li>
                        <li><strong>GPT-5 chat (latest)</strong> - Most current version</li>
                    </ul>
                </div>
                
                <div class="models-card">
                    <h4>GPT-4.1 & GPT-4o Family</h4>
                    <ul>
                        <li><strong>GPT-4.1</strong> - Enhanced reasoning capabilities</li>
                        <li><strong>GPT-4.1 mini</strong> - Compact version</li>
                        <li><strong>GPT-4.1 nano</strong> - Smallest, fastest</li>
                        <li><strong>GPT-4o</strong> - Optimized for conversations</li>
                        <li><strong>GPT-4o mini</strong> - Cost-effective option</li>
                    </ul>
                </div>
                
                <div class="models-card">
                    <h4>Legacy Models</h4>
                    <ul>
                        <li><strong>GPT-4 Turbo</strong> - Previous generation flagship</li>
                        <li><strong>GPT-4</strong> - Original GPT-4</li>
                        <li><strong>GPT-3.5 Turbo</strong> - Fast, economical choice</li>
                        <li><strong>GPT-3.5 Turbo 16k</strong> - Extended context window</li>
                    </ul>
                </div>
            </div>

            <h2>Available O-Series Models</h2>
            
            <div class="models-grid">
                <div class="models-card reasoning">
                    <h4>Premium Reasoning</h4>
                    <ul>
                        <li><strong>o1-pro</strong> - Most advanced reasoning model</li>
                        <li><strong>o3-pro</strong> - Latest professional reasoning</li>
                    </ul>
                </div>
                
                <div class="models-card reasoning">
                    <h4>Standard Reasoning</h4>
                    <ul>
                        <li><strong>o1</strong> - Original reasoning model</li>
                        <li><strong>o3</strong> - Advanced reasoning <span class="models-flex-badge">Flex</span></li>
                    </ul>
                </div>
                
                <div class="models-card reasoning">
                    <h4>Compact Reasoning</h4>
                    <ul>
                        <li><strong>o1-mini</strong> - Faster, more affordable</li>
                        <li><strong>o3-mini</strong> - Latest compact version</li>
                        <li><strong>o4-mini</strong> - Next-generation compact <span class="models-flex-badge">Flex</span></li>
                    </ul>
                </div>
            </div>

            <h2>Flex vs Standard Pricing</h2>
            
            <h3>Standard Pricing</h3>
            <p>Immediate responses with full priority processing. Best when you need answers right away for time-sensitive work, live conversations, or urgent tasks.</p>
            
            <h3>Flex Pricing (50% savings)</h3>
            <p>Responses may take longer as your request is processed when server capacity is available. Perfect for non-urgent tasks like content generation, research, analysis, or any work where you can wait a bit for significant cost savings.</p>
            
            <p><strong>Flex-supported models:</strong> GPT-5, GPT-5 mini, GPT-5 nano, o3, and o4-mini</p>

            <h2>Model Controls</h2>

            <h3>Temperature (Chat Models)</h3>
            <p>Controls creativity and randomness in responses:</p>
            <ul>
                <li><strong>0.0-0.3:</strong> Focused, consistent, factual responses</li>
                <li><strong>0.4-0.7:</strong> Balanced creativity and accuracy (default)</li>
                <li><strong>0.8-2.0:</strong> Creative, varied, experimental outputs</li>
            </ul>

            <h3>Effort Levels (O-Series Models)</h3>
            <p>Determines how much computational "thinking" the model does:</p>
            <ul>
                <li><strong>Low:</strong> Faster responses, suitable for simpler reasoning tasks</li>
                <li><strong>Medium:</strong> Balanced speed and depth (recommended default)</li>
                <li><strong>Hard:</strong> Maximum reasoning power for the most complex problems</li>
            </ul>

            <h2>Context Windows & Tokens</h2>

            <h3>What are tokens?</h3>
            <p>Tokens are pieces of text the AI processes. Roughly 1 token = 0.75 words in English. Both your input and the AI's response count toward token usage.</p>

            <h3>Context Window</h3>
            <p>The maximum amount of text (in tokens) the model can consider at once, including:</p>
            <ul>
                <li>Your permanent memory settings</li>
                <li>Previous conversation history (if context is enabled)</li>
                <li>Your current message</li>
                <li>Space reserved for the AI's response</li>
            </ul>

            <h3>Model Limits</h3>
            <ul>
                <li><strong>Legacy models (GPT-3.5, GPT-4):</strong> 8K-16K tokens</li>
                <li><strong>GPT-4o family:</strong> 128K tokens (~96,000 words)</li>
                <li><strong>GPT-4.1 & GPT-5 families:</strong> 400K-1M tokens (~300K-750K words)</li>
                <li><strong>O-series models:</strong> 128K-200K tokens (~96K-150K words)</li>
            </ul>

            <h2>Choosing the Right Model</h2>

            <h3>For everyday conversations and tasks:</h3>
            <ul>
                <li><strong>GPT-5 nano (Flex)</strong> - Most economical for simple questions</li>
                <li><strong>GPT-4o mini</strong> - Good balance of speed and capability</li>
                <li><strong>GPT-5</strong> - Best overall chat model</li>
            </ul>

            <h3>For complex reasoning and analysis:</h3>
            <ul>
                <li><strong>o3-mini</strong> - Affordable reasoning for most tasks</li>
                <li><strong>o3</strong> - Advanced reasoning with Flex option</li>
                <li><strong>o3-pro</strong> - Maximum reasoning power for critical work</li>
            </ul>

            <h3>For cost optimization:</h3>
            <ul>
                <li>Use <strong>Flex pricing</strong> when you can wait</li>
                <li>Disable context window for unrelated questions</li>
                <li>Choose "nano" or "mini" models for simple tasks</li>
                <li>Set appropriate temperature/effort levels</li>
            </ul>

            <div class="legal-footer">
                <p><strong>Ready to explore our models?</strong> <a href="{{ '/pricing' | relative_url }}">View detailed pricing</a> or <a href="https://apps.apple.com/app/id6751123527" target="_blank" rel="noopener">download Lookinglass</a> to start experimenting.</p>
            </div>
        </div>
    </div>
</section>

<style>
.models-comparison {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 2rem;
    margin: 2rem 0;
}

.models-type-card {
    background-color: var(--surface-color);
    padding: 2rem;
    border-radius: 1rem;
    border: 1px solid var(--border-color);
}

.models-type-card h3 {
    color: var(--primary-color);
    margin-bottom: 1rem;
}

.models-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin: 2rem 0;
}

.models-card {
    background-color: var(--surface-color);
    padding: 1.5rem;
    border-radius: 0.75rem;
    border: 1px solid var(--border-color);
}

.models-card.reasoning {
    border-left: 4px solid var(--warning);
}

.models-card h4 {
    color: var(--primary-color);
    margin-bottom: 1rem;
}

.models-card ul {
    margin-left: 0;
    list-style: none;
}

.models-card li {
    padding: 0.25rem 0;
    color: var(--text-secondary);
}

.models-flex-badge {
    background-color: var(--success);
    color: white;
    font-size: 0.75rem;
    padding: 0.25rem 0.5rem;
    border-radius: 1rem;
    font-weight: 500;
    margin-left: 0.5rem;
}

@media (max-width: 768px) {
    .models-comparison {
        grid-template-columns: 1fr;
    }
    
    .models-grid {
        grid-template-columns: 1fr;
    }
}</style>